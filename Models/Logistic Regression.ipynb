{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n#read data set\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n#x_train = train.drop(['species', 'id'], axis=1).values\n#le = LabelEncoder().fit(train['species'])\n#y_train = le.transform(train['species'])\n#x_test = test.drop(['id'], axis=1).values\n    \ndef encode(train, test):\n    le = LabelEncoder().fit(train.species) \n    y_train = le.transform(train.species)           # encode species strings\n    classes = list(le.classes_)                    # save column names for submission\n    test_ids = test.id                             # save test ids for submission\n    \n    x_train = train.drop(['species', 'id'], axis=1)  \n    x_test = test.drop(['id'], axis=1)\n    \n    return x_train, y_train, x_test, test_ids, classes\n\nx_train, y_train, x_test , test_ids, classes = encode(train, test)\n\nscaler = StandardScaler().fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Logistic Regression with Grid Search CV\n        \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n#set a seed\nseed = 42\n\n#Logistic regression model\nlog_reg= LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n          class_weight=None, random_state=seed, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=1, warm_start=True, n_jobs= -1)\n\n#Tuning the hyperparameters \"C\" which is the inverse of hyperparameter strength and \"tol\" which is tolerance for stopping criteria with GridSearchCV\nclassifier = GridSearchCV(log_reg, param_grid = {'C':[0.1,0.5,1,10, 50, 100, 500, 1000, 2000], 'tol': [0.001, 0.005,0.0001]}, scoring='neg_log_loss', refit='True', n_jobs=1, cv=10)\n\n# Fit model.\nclassifier.fit(x_train,y_train)\n\n# Make prediction for test data\ny = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)\n\nsubmission = pd.DataFrame(y_prob, columns=classes)\nsubmission.insert(0, 'id', test_ids)\nsubmission.reset_index()\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}