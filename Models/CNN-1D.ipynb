{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sunsh\\AppData\\Local\\conda\\conda\\envs\\python-CZ4041\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sunsh\\AppData\\Local\\conda\\conda\\envs\\python-CZ4041\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sunsh\\AppData\\Local\\conda\\conda\\envs\\python-CZ4041\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 891 samples, validate on 99 samples\n",
      "Epoch 1/100\n",
      "891/891 [==============================] - 5s 6ms/step - loss: 4.2281 - acc: 0.1167 - val_loss: 3.2018 - val_acc: 0.4444\n",
      "Epoch 2/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.1409 - acc: 0.6453 - val_loss: 1.0596 - val_acc: 0.8889\n",
      "Epoch 3/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.6252 - acc: 0.8956 - val_loss: 0.3817 - val_acc: 0.9394\n",
      "Epoch 4/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.2158 - acc: 0.9686 - val_loss: 0.1811 - val_acc: 0.9798\n",
      "Epoch 5/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0917 - acc: 0.9899 - val_loss: 0.0906 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0486 - acc: 0.9921 - val_loss: 0.0790 - val_acc: 0.9899\n",
      "Epoch 7/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0324 - acc: 0.9955 - val_loss: 0.0916 - val_acc: 0.9798\n",
      "Epoch 8/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0775 - acc: 0.9877 - val_loss: 0.1747 - val_acc: 0.9596\n",
      "Epoch 9/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0494 - acc: 0.9910 - val_loss: 0.0644 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0411 - acc: 0.9944 - val_loss: 0.0512 - val_acc: 0.9899\n",
      "Epoch 11/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0141 - acc: 0.9978 - val_loss: 0.0504 - val_acc: 0.9798\n",
      "Epoch 12/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0095 - acc: 0.9989 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9899\n",
      "Epoch 14/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 9.2815e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 8.6609e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 8.1158e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 8.3485e-04 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 7.0528e-04 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 6.7651e-04 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 6.8392e-04 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 6.1409e-04 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 6.4297e-04 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 5.8702e-04 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 5.7625e-04 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 5.2051e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 5.0074e-04 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 5.2121e-04 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.7951e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.8132e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.3166e-04 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.2249e-04 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.3654e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.1024e-04 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.1771e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.6065e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.7316e-04 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.3492e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.6405e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.1070e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.0926e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.0753e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.9392e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.0140e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.0231e-04 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 3.0034e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.4813e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.4104e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.2379e-04 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.1898e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.2090e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.1047e-04 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.1099e-04 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.0300e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.0181e-04 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.0446e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.8597e-04 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.8269e-04 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.6494e-04 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.8862e-04 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.7291e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.6091e-04 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.5462e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.5827e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.5083e-04 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.6120e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.4927e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.3718e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.3285e-04 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.3166e-04 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.3459e-04 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.2406e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.4588e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.2513e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.1903e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.1263e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.0871e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.0893e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.0887e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d1e23eccc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout, MaxPooling1D, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "seed(3141593)\n",
    "set_random_seed(3141593)\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "def encode(train, test):\n",
    "    label_encoder = LabelEncoder().fit(train.species)\n",
    "    labels = label_encoder.transform(train.species)\n",
    "    classes = list(label_encoder.classes_)\n",
    "\n",
    "    train = train.drop(['species', 'id'], axis=1)\n",
    "    test = test.drop('id', axis=1)\n",
    "\n",
    "    return train, labels, test, classes\n",
    "\n",
    "train, labels, test, classes = encode(train, test)\n",
    "\n",
    "# standardize train features\n",
    "scaler = StandardScaler().fit(train.values)\n",
    "scaled_train = scaler.transform(train.values)\n",
    "scaled_test = scaler.transform(test)\n",
    "\n",
    "# split train data into train and validation\n",
    "sss = StratifiedShuffleSplit(test_size=0.1, random_state=123)\n",
    "for train_index, valid_index in sss.split(scaled_train, labels):\n",
    "    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n",
    "    y_train, y_valid = labels[train_index], labels[valid_index]\n",
    "\n",
    "feature_number = 64\n",
    "class_number = len(classes)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, class_number)\n",
    "y_valid = np_utils.to_categorical(y_valid, class_number)    \n",
    "\n",
    "# reshape train data\n",
    "X_train_r = np.zeros((len(X_train), feature_number, 3))\n",
    "X_train_r[:, :, 0] = X_train[:, :feature_number]\n",
    "X_train_r[:, :, 1] = X_train[:, feature_number:128]\n",
    "X_train_r[:, :, 2] = X_train[:, 128:]\n",
    "\n",
    "# reshape validation data\n",
    "X_valid_r = np.zeros((len(X_valid), feature_number, 3))\n",
    "X_valid_r[:, :, 0] = X_valid[:, :feature_number]\n",
    "X_valid_r[:, :, 1] = X_valid[:, feature_number:128]\n",
    "X_valid_r[:, :, 2] = X_valid[:, 128:]\n",
    "\n",
    "# reshape y train data\n",
    "y_train_all = [[0 for i in range(99)] for j in range(990)]\n",
    "for i, label in enumerate(labels):\n",
    "    y_train_all[i][label] = 1\n",
    "y_train_all = np.array(y_train_all)\n",
    "\n",
    "# reshape test data\n",
    "test_r = np.zeros((len(scaled_test), feature_number, 3))\n",
    "test_r[:, :, 0] = scaled_test[:, :feature_number]\n",
    "test_r[:, :, 1] = scaled_test[:, feature_number:128]\n",
    "test_r[:, :, 2] = scaled_test[:, 128:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(input_shape=(64, 3), filters=1024, kernel_size=6))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate = 1 - 0.2))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(class_number))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam = Adam(lr=1e-4, decay=1e-5)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_r, y_train, epochs=100, validation_data=(X_valid_r, y_valid), batch_size=32, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_r)\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "submission = pd.DataFrame(data = pred)\n",
    "submission.columns = sample_sub.columns[1:]\n",
    "submission['id'] = sample_sub['id']\n",
    "submission.to_csv(\"submission.csv\", sep=',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
